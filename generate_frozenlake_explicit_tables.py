#!/usr/bin/env python3
"""
ä¸º frozenlak_explicit æ–‡ä»¶å¤¹ä¸­çš„æ¯ä¸ªç‰ˆæœ¬ï¼ˆv0-v4ï¼‰å•ç‹¬ç”Ÿæˆè¡¨æ ¼ã€‚

å‚è€ƒ generate_all_tables_split.py çš„é€»è¾‘ã€‚
æ¯ä¸ªç‰ˆæœ¬ç”Ÿæˆä¸€ä¸ªç‹¬ç«‹çš„ CSV è¡¨æ ¼æ–‡ä»¶ã€‚
"""

import csv
from pathlib import Path
from collections import defaultdict

# é…ç½®
BASE_DIR = Path("/data/xingkun/experiment_result/frozenlak_explicit")
OUTPUT_DIR = Path("/data/xingkun/experiment_result")

# ç‰ˆæœ¬åˆ—è¡¨
VERSIONS = ["v0", "v1", "v2", "v3", "v4"]

# æ¨¡å‹æ˜ å°„: æ–‡ä»¶å¤¹åç§°æ¨¡å¼ -> (logæ–‡ä»¶å¤¹ä¸­çš„æ¨¡å‹å, æ˜¾ç¤ºåç§°)
# ä¸åŒç‰ˆæœ¬çš„æ–‡ä»¶å¤¹å‘½åå¯èƒ½ä¸åŒï¼Œéœ€è¦çµæ´»åŒ¹é…
MODEL_PATTERNS = {
    "llama3.1_8b": (["llama3.1-8b", "llama3.1_8b"], "Llama3.1-8B"),
    "llama-3.3-70b": (["llama-3.3-70b-instruct", "llama-3.3-70b"], "Llama3.3-70B"),
    "qwen2.5-7b": (["qwen2.5-7b", "qwen2.5-7b-instruct"], "Qwen2.5-7B"),
    "qwen3-30b": (["qwen3-30b", "qwen3-30b-instruct"], "Qwen3-30B"),
    "gpt4o": (["gpt-4o", "gpt4o"], "GPT-4o"),
    "grok-3": (["grok-3"], "Grok-3"),
    "deepseek-r1": (["deepseek-r1"], "DeepSeek-R1"),
}

# æ–¹æ³•åˆ—è¡¨
METHODS = [
    "generative_True_False",
    "generative_True_True",
    "memorybank_True_False",
    "memorybank_True_True",
    "vanilla_False_False",
    "vanilla_True_False",
    "vanilla_True_True",
    "voyager_True_False",
    "voyager_True_True",
]

# æ–¹æ³•æ˜ å°„: (memory_type, use_memory, use_glove) -> row_name
METHOD_TO_ROW = {
    ("vanilla", "False", "False"): "no-memory",
    ("vanilla", "True", "False"): "vanilla",
    ("vanilla", "True", "True"): "vanilla-glove",
    ("memorybank", "True", "False"): "memorybank",
    ("memorybank", "True", "True"): "memorybank-glove",
    ("voyager", "True", "False"): "voyager",
    ("voyager", "True", "True"): "voyager-glove",
    ("generative", "True", "False"): "generative",
    ("generative", "True", "True"): "generative-glove",
}

# è¡Œé¡ºåº
ROW_ORDER = [
    "no-memory",
    "vanilla", "vanilla-glove",
    "memorybank", "memorybank-glove",
    "voyager", "voyager-glove",
    "generative", "generative-glove",
]

# æ¨¡å‹æ˜¾ç¤ºé¡ºåº
MODEL_ORDER = [
    "Llama3.1-8B",
    "Llama3.3-70B",
    "Qwen2.5-7B",
    "Qwen3-30B",
    "GPT-4o",
    "Grok-3",
    "DeepSeek-R1",
]

# æœ€å°æ•°æ®ç‚¹è¦æ±‚
MIN_DATA_POINTS = 20


def parse_method(method: str) -> tuple:
    """è§£ææ–¹æ³•å­—ç¬¦ä¸²ä¸º (memory_type, use_memory, use_glove)"""
    parts = method.split("_")
    return (parts[0], parts[1], parts[2])


def extract_scores_from_csv(csv_path: Path) -> list:
    """ä»CSVæ–‡ä»¶æå–æœ€åä¸€åˆ—çš„åˆ†æ•°"""
    values = []
    try:
        with open(csv_path, "r", encoding="utf-8") as f:
            reader = csv.reader(f)
            next(reader, None)  # è·³è¿‡æ ‡é¢˜è¡Œ
            for row in reader:
                if row:
                    try:
                        values.append(float(row[-1]))
                    except ValueError:
                        pass
    except Exception as e:
        print(f"  è¯»å– {csv_path} å¤±è´¥: {e}")
    return values


def calculate_average(values: list) -> float | None:
    """è®¡ç®—å¹³å‡å€¼ï¼Œå¦‚æœæ•°æ®ç‚¹å°‘äº MIN_DATA_POINTS åˆ™è¿”å› None"""
    if len(values) >= MIN_DATA_POINTS:
        return sum(values) / len(values)
    return None


def find_model_folder(version_dir: Path, model_key: str) -> Path | None:
    """æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶å¤¹"""
    if not version_dir.exists():
        return None
    
    for item in version_dir.iterdir():
        if not item.is_dir():
            continue
        item_name = item.name.lower()
        
        # åŒ¹é…æ¨¡å‹å…³é”®å­—
        if model_key.lower() in item_name:
            return item
    
    return None


def find_log_folder(model_folder: Path, model_variants: list, method: str) -> Path | None:
    """æŸ¥æ‰¾æ—¥å¿—æ–‡ä»¶å¤¹"""
    for variant in model_variants:
        log_name = f"log_frozenlake_{variant}_{method}"
        log_folder = model_folder / log_name
        if log_folder.exists():
            return log_folder
    
    # å°è¯•æœç´¢åŒ…å«æ–¹æ³•åçš„æ–‡ä»¶å¤¹
    for item in model_folder.iterdir():
        if item.is_dir() and method in item.name:
            return item
    
    return None


def process_version(version: str) -> dict:
    """å¤„ç†å•ä¸ªç‰ˆæœ¬ï¼Œè¿”å›æ•°æ®å­—å…¸"""
    version_dir = BASE_DIR / version
    print(f"\nå¤„ç†ç‰ˆæœ¬: {version}")
    
    if not version_dir.exists():
        print(f"  ç‰ˆæœ¬ç›®å½•ä¸å­˜åœ¨: {version_dir}")
        return {}
    
    # æ•°æ®ç»“æ„: data[display_name][row_name] = average_score
    data = defaultdict(dict)
    
    for model_key, (model_variants, display_name) in MODEL_PATTERNS.items():
        model_folder = find_model_folder(version_dir, model_key)
        if not model_folder:
            print(f"  æœªæ‰¾åˆ°æ¨¡å‹: {model_key}")
            continue
        
        print(f"  å¤„ç†æ¨¡å‹: {display_name} ({model_folder.name})")
        
        for method in METHODS:
            log_folder = find_log_folder(model_folder, model_variants, method)
            if not log_folder:
                continue
            
            csv_path = log_folder / "log" / "explorer_summary.csv"
            if not csv_path.exists():
                continue
            
            # è§£ææ–¹æ³•è·å–è¡Œå
            memory_type, use_memory, use_glove = parse_method(method)
            row_name = METHOD_TO_ROW.get((memory_type, use_memory, use_glove))
            if not row_name:
                continue
            
            # æå–åˆ†æ•°å¹¶è®¡ç®—å¹³å‡å€¼
            values = extract_scores_from_csv(csv_path)
            avg = calculate_average(values)
            
            if avg is not None:
                data[display_name][row_name] = avg
                print(f"    {row_name}: {avg:.4f} ({len(values)} æ•°æ®ç‚¹)")
            else:
                print(f"    {row_name}: æ•°æ®ä¸è¶³ ({len(values)} æ•°æ®ç‚¹)")
    
    return data


def write_version_csv(version: str, data: dict, output_file: Path):
    """ä¸ºå•ä¸ªç‰ˆæœ¬å†™å…¥ CSV æ–‡ä»¶"""
    with open(output_file, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        
        # è·å–è¯¥ç‰ˆæœ¬ä¸­å­˜åœ¨çš„æ¨¡å‹ï¼ˆæŒ‰é¡ºåºï¼‰
        available_models = [m for m in MODEL_ORDER if m in data]
        
        if not available_models:
            print(f"  {version} æ²¡æœ‰å¯ç”¨æ•°æ®ï¼Œè·³è¿‡ç”Ÿæˆè¡¨æ ¼")
            return
        
        # æ ‡é¢˜è¡Œ1: ç‰ˆæœ¬ä¿¡æ¯
        writer.writerow([f"FrozenLake Explicit - {version}"] + [""] * len(available_models))
        
        # æ ‡é¢˜è¡Œ2: æ¨¡å‹åç§°
        writer.writerow(["Method"] + available_models)
        
        # æ•°æ®è¡Œ
        for row_name in ROW_ORDER:
            row_data = [row_name]
            for model in available_models:
                score = data.get(model, {}).get(row_name)
                if score is not None:
                    row_data.append(f"{score:.4f}")
                else:
                    row_data.append("")
            writer.writerow(row_data)
    
    print(f"  ç”Ÿæˆ: {output_file}")


def write_summary_csv(all_data: dict, output_file: Path):
    """ç”Ÿæˆæ±‡æ€»è¡¨æ ¼ï¼ŒåŒ…å«æ‰€æœ‰ç‰ˆæœ¬"""
    with open(output_file, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        
        # æ ‡é¢˜è¡Œ1
        header1 = ["FrozenLake Explicit Summary"]
        for version in VERSIONS:
            header1.extend([version] + [""] * (len(MODEL_ORDER) - 1))
        writer.writerow(header1)
        
        # æ ‡é¢˜è¡Œ2: æ¨¡å‹åç§°ï¼ˆæ¯ä¸ªç‰ˆæœ¬é‡å¤ï¼‰
        header2 = ["Method"]
        for version in VERSIONS:
            header2.extend(MODEL_ORDER)
        writer.writerow(header2)
        
        # æ•°æ®è¡Œ
        for row_name in ROW_ORDER:
            row_data = [row_name]
            for version in VERSIONS:
                version_data = all_data.get(version, {})
                for model in MODEL_ORDER:
                    score = version_data.get(model, {}).get(row_name)
                    if score is not None:
                        row_data.append(f"{score:.4f}")
                    else:
                        row_data.append("")
            writer.writerow(row_data)
    
    print(f"\nç”Ÿæˆæ±‡æ€»è¡¨æ ¼: {output_file}")


def main():
    print("ğŸ” å¼€å§‹ä¸º frozenlak_explicit æ¯ä¸ªç‰ˆæœ¬ç”Ÿæˆè¡¨æ ¼...")
    
    all_data = {}
    
    # å¤„ç†æ¯ä¸ªç‰ˆæœ¬
    for version in VERSIONS:
        data = process_version(version)
        all_data[version] = data
        
        # ä¸ºæ¯ä¸ªç‰ˆæœ¬ç”Ÿæˆå•ç‹¬çš„è¡¨æ ¼
        if data:
            output_file = OUTPUT_DIR / f"table_frozenlake_explicit_{version}.csv"
            write_version_csv(version, data, output_file)
    
    # ç”Ÿæˆæ±‡æ€»è¡¨æ ¼
    summary_file = OUTPUT_DIR / "table_frozenlake_explicit_summary.csv"
    write_summary_csv(all_data, summary_file)
    
    print("\nâœ… å®Œæˆï¼")


if __name__ == "__main__":
    main()
