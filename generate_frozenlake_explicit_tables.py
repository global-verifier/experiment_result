#!/usr/bin/env python3
"""
ä¸º frozenlak_explicit æ–‡ä»¶å¤¹ä¸­çš„æ¯ä¸ªç‰ˆæœ¬ï¼ˆv0-v4ï¼‰å•ç‹¬ç”Ÿæˆè¡¨æ ¼ã€‚

å‚è€ƒ generate_all_tables_split.py çš„é€»è¾‘ã€‚
æ¯ä¸ªç‰ˆæœ¬ç”Ÿæˆä¸€ä¸ªç‹¬ç«‹çš„ CSV è¡¨æ ¼æ–‡ä»¶ã€‚
æ•°æ®æŒ‰ 20 ä¸ªä¸€ç»„åˆ†æˆ env0, env1, env2ã€‚
"""

import csv
from pathlib import Path
from collections import defaultdict

# é…ç½®
BASE_DIR = Path("/data/xingkun/experiment_result/frozenlak_explicit")
OUTPUT_DIR = Path("/data/xingkun/experiment_result")

# ç‰ˆæœ¬åˆ—è¡¨
VERSIONS = ["v0", "v1", "v2", "v3", "v4"]

# æ¨¡å‹æ˜ å°„: æ–‡ä»¶å¤¹åç§°æ¨¡å¼ -> (logæ–‡ä»¶å¤¹ä¸­çš„æ¨¡å‹å, æ˜¾ç¤ºåç§°)
# ä¸åŒç‰ˆæœ¬çš„æ–‡ä»¶å¤¹å‘½åå¯èƒ½ä¸åŒï¼Œéœ€è¦çµæ´»åŒ¹é…
MODEL_PATTERNS = {
    "llama3.1_8b": (["llama3.1-8b", "llama3.1_8b"], "Llama3.1-8B"),
    "llama-3.3-70b": (["llama-3.3-70b-instruct", "llama-3.3-70b"], "Llama3.3-70B"),
    "qwen2.5-7b": (["qwen2.5-7b", "qwen2.5-7b-instruct"], "Qwen2.5-7B"),
    "qwen3-30b": (["qwen3-30b", "qwen3-30b-instruct"], "Qwen3-30B"),
    "gpt4o": (["gpt-4o", "gpt4o"], "GPT-4o"),
    "grok-3": (["grok-3"], "Grok-3"),
    "deepseek-r1": (["deepseek-r1"], "DeepSeek-R1"),
    "deepseek-v3.2": (["deepseek-v3.2"], "DeepSeek-V3.2"),
}

# æ–¹æ³•åˆ—è¡¨
METHODS = [
    "generative_True_False",
    "generative_True_True",
    "memorybank_True_False",
    "memorybank_True_True",
    "vanilla_False_False",
    "vanilla_True_False",
    "vanilla_True_True",
    "voyager_True_False",
    "voyager_True_True",
]

# æ–¹æ³•æ˜ å°„: (memory_type, use_memory, use_glove) -> row_name
METHOD_TO_ROW = {
    ("vanilla", "False", "False"): "no-memory",
    ("vanilla", "True", "False"): "vanilla",
    ("vanilla", "True", "True"): "vanilla-glove",
    ("memorybank", "True", "False"): "memorybank",
    ("memorybank", "True", "True"): "memorybank-glove",
    ("voyager", "True", "False"): "voyager",
    ("voyager", "True", "True"): "voyager-glove",
    ("generative", "True", "False"): "generative",
    ("generative", "True", "True"): "generative-glove",
}

# è¡Œé¡ºåº
ROW_ORDER = [
    "no-memory",
    "vanilla", "vanilla-glove",
    "memorybank", "memorybank-glove",
    "voyager", "voyager-glove",
    "generative", "generative-glove",
]

# æ¨¡å‹æ˜¾ç¤ºé¡ºåº
MODEL_ORDER = [
    "Llama3.1-8B",
    "Llama3.3-70B",
    "Qwen2.5-7B",
    "Qwen3-30B",
    "GPT-4o",
    "Grok-3",
    "DeepSeek-R1",
    "DeepSeek-V3.2",
]

# æœ€å°æ•°æ®ç‚¹è¦æ±‚
MIN_DATA_POINTS = 20
ITEMS_PER_ENV = 20


def parse_method(method: str) -> tuple:
    """è§£ææ–¹æ³•å­—ç¬¦ä¸²ä¸º (memory_type, use_memory, use_glove)"""
    parts = method.split("_")
    return (parts[0], parts[1], parts[2])


def extract_scores_from_csv(csv_path: Path) -> list:
    """ä»CSVæ–‡ä»¶æå–æœ€åä¸€åˆ—çš„åˆ†æ•°"""
    values = []
    try:
        with open(csv_path, "r", encoding="utf-8") as f:
            reader = csv.reader(f)
            next(reader, None)  # è·³è¿‡æ ‡é¢˜è¡Œ
            for row in reader:
                if row:
                    try:
                        values.append(float(row[-1]))
                    except ValueError:
                        pass
    except Exception as e:
        print(f"  è¯»å– {csv_path} å¤±è´¥: {e}")
    return values


def calculate_env_averages(values: list, items_per_env: int = ITEMS_PER_ENV) -> list:
    """
    è®¡ç®—æ¯ä¸ªç¯å¢ƒçš„å¹³å‡å€¼ã€‚
    å°†æ•°æ®æŒ‰ items_per_env åˆ†ç»„ï¼Œè¿”å› [env0_avg, env1_avg, env2_avg]ã€‚
    å¦‚æœæŸä¸ªç¯å¢ƒçš„æ•°æ®ç‚¹å°‘äº MIN_DATA_POINTSï¼Œè¿”å› None è¡¨ç¤ºè¯¥ç¯å¢ƒæ•°æ®ä¸å…¨ã€‚
    """
    averages = []
    for i in range(0, len(values), items_per_env):
        chunk = values[i:i + items_per_env]
        if len(chunk) >= MIN_DATA_POINTS:
            avg = sum(chunk) / len(chunk)
            averages.append(avg)
        else:
            averages.append(None)  # æ•°æ®ä¸å…¨ï¼Œç•™ç©º
    return averages


def find_model_folder(version_dir: Path, model_key: str) -> Path | None:
    """æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶å¤¹"""
    if not version_dir.exists():
        return None
    
    for item in version_dir.iterdir():
        if not item.is_dir():
            continue
        item_name = item.name.lower()
        
        # åŒ¹é…æ¨¡å‹å…³é”®å­—
        if model_key.lower() in item_name:
            return item
    
    return None


def find_log_folder(model_folder: Path, model_variants: list, method: str) -> Path | None:
    """æŸ¥æ‰¾æ—¥å¿—æ–‡ä»¶å¤¹"""
    for variant in model_variants:
        log_name = f"log_frozenlake_{variant}_{method}"
        log_folder = model_folder / log_name
        if log_folder.exists():
            return log_folder
    
    # å°è¯•æœç´¢åŒ…å«æ–¹æ³•åçš„æ–‡ä»¶å¤¹
    for item in model_folder.iterdir():
        if item.is_dir() and method in item.name:
            return item
    
    return None


def process_version(version: str) -> dict:
    """å¤„ç†å•ä¸ªç‰ˆæœ¬ï¼Œè¿”å›æ•°æ®å­—å…¸"""
    version_dir = BASE_DIR / version
    print(f"\nå¤„ç†ç‰ˆæœ¬: {version}")
    
    if not version_dir.exists():
        print(f"  ç‰ˆæœ¬ç›®å½•ä¸å­˜åœ¨: {version_dir}")
        return {}
    
    # æ•°æ®ç»“æ„: data[display_name][row_name] = [env0_avg, env1_avg, env2_avg]
    data = defaultdict(dict)
    
    for model_key, (model_variants, display_name) in MODEL_PATTERNS.items():
        model_folder = find_model_folder(version_dir, model_key)
        if not model_folder:
            print(f"  æœªæ‰¾åˆ°æ¨¡å‹: {model_key}")
            continue
        
        print(f"  å¤„ç†æ¨¡å‹: {display_name} ({model_folder.name})")
        
        for method in METHODS:
            log_folder = find_log_folder(model_folder, model_variants, method)
            if not log_folder:
                continue
            
            csv_path = log_folder / "log" / "explorer_summary.csv"
            if not csv_path.exists():
                continue
            
            # è§£ææ–¹æ³•è·å–è¡Œå
            memory_type, use_memory, use_glove = parse_method(method)
            row_name = METHOD_TO_ROW.get((memory_type, use_memory, use_glove))
            if not row_name:
                continue
            
            # æå–åˆ†æ•°å¹¶è®¡ç®—æ¯ä¸ªç¯å¢ƒçš„å¹³å‡å€¼
            values = extract_scores_from_csv(csv_path)
            env_averages = calculate_env_averages(values, ITEMS_PER_ENV)
            
            data[display_name][row_name] = env_averages
            
            # æ‰“å°è°ƒè¯•ä¿¡æ¯
            avg_strs = [f"{a:.4f}" if a is not None else "N/A" for a in env_averages]
            print(f"    {row_name}: {avg_strs} ({len(values)} æ•°æ®ç‚¹)")
    
    return data


def write_version_csv(version: str, data: dict, output_file: Path):
    """ä¸ºå•ä¸ªç‰ˆæœ¬å†™å…¥ CSV æ–‡ä»¶"""
    with open(output_file, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        
        # è·å–è¯¥ç‰ˆæœ¬ä¸­å­˜åœ¨çš„æ¨¡å‹ï¼ˆæŒ‰é¡ºåºï¼‰
        available_models = [m for m in MODEL_ORDER if m in data]
        
        if not available_models:
            print(f"  {version} æ²¡æœ‰å¯ç”¨æ•°æ®ï¼Œè·³è¿‡ç”Ÿæˆè¡¨æ ¼")
            return
        
        # æ ‡é¢˜è¡Œ1: ç‰ˆæœ¬ä¿¡æ¯
        header1 = [f"FrozenLake Explicit - {version}"]
        for model in available_models:
            header1.extend([model, "", ""])
        writer.writerow(header1)
        
        # æ ‡é¢˜è¡Œ2: env0, env1, env2 (æ¯ä¸ªæ¨¡å‹é‡å¤)
        header2 = ["Method"]
        for _ in available_models:
            header2.extend(["env0", "env1", "env2"])
        writer.writerow(header2)
        
        # æ•°æ®è¡Œ
        for row_name in ROW_ORDER:
            row_data = [row_name]
            for model in available_models:
                env_averages = data.get(model, {}).get(row_name, [])
                for i in range(3):
                    if i < len(env_averages) and env_averages[i] is not None:
                        row_data.append(f"{env_averages[i]:.4f}")
                    else:
                        row_data.append("")
            writer.writerow(row_data)
    
    print(f"  ç”Ÿæˆ: {output_file}")


def write_summary_csv(all_data: dict, output_file: Path):
    """ç”Ÿæˆæ±‡æ€»è¡¨æ ¼ï¼ŒåŒ…å«æ‰€æœ‰ç‰ˆæœ¬"""
    with open(output_file, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        
        # æ ‡é¢˜è¡Œ1: ç‰ˆæœ¬
        header1 = [""]
        for version in VERSIONS:
            # æ¯ä¸ªç‰ˆæœ¬æœ‰ 7 ä¸ªæ¨¡å‹ Ã— 3 ä¸ª env = 21 åˆ—
            header1.extend([version] + [""] * (len(MODEL_ORDER) * 3 - 1))
        writer.writerow(header1)
        
        # æ ‡é¢˜è¡Œ2: æ¨¡å‹åç§°ï¼ˆæ¯ä¸ªç‰ˆæœ¬é‡å¤ï¼‰
        header2 = [""]
        for version in VERSIONS:
            for model in MODEL_ORDER:
                header2.extend([model, "", ""])
        writer.writerow(header2)
        
        # æ ‡é¢˜è¡Œ3: env0, env1, env2
        header3 = ["Method"]
        for version in VERSIONS:
            for _ in MODEL_ORDER:
                header3.extend(["env0", "env1", "env2"])
        writer.writerow(header3)
        
        # æ•°æ®è¡Œ
        for row_name in ROW_ORDER:
            row_data = [row_name]
            for version in VERSIONS:
                version_data = all_data.get(version, {})
                for model in MODEL_ORDER:
                    env_averages = version_data.get(model, {}).get(row_name, [])
                    for i in range(3):
                        if i < len(env_averages) and env_averages[i] is not None:
                            row_data.append(f"{env_averages[i]:.4f}")
                        else:
                            row_data.append("")
            writer.writerow(row_data)
    
    print(f"\nç”Ÿæˆæ±‡æ€»è¡¨æ ¼: {output_file}")


def main():
    print("ğŸ” å¼€å§‹ä¸º frozenlak_explicit æ¯ä¸ªç‰ˆæœ¬ç”Ÿæˆè¡¨æ ¼ï¼ˆåˆ† env0/env1/env2ï¼‰...")
    
    all_data = {}
    
    # å¤„ç†æ¯ä¸ªç‰ˆæœ¬
    for version in VERSIONS:
        data = process_version(version)
        all_data[version] = data
        
        # ä¸ºæ¯ä¸ªç‰ˆæœ¬ç”Ÿæˆå•ç‹¬çš„è¡¨æ ¼
        if data:
            output_file = OUTPUT_DIR / f"table_frozenlake_explicit_{version}.csv"
            write_version_csv(version, data, output_file)
    
    # ç”Ÿæˆæ±‡æ€»è¡¨æ ¼
    summary_file = OUTPUT_DIR / "table_frozenlake_explicit_summary.csv"
    write_summary_csv(all_data, summary_file)
    
    print("\nâœ… å®Œæˆï¼")


if __name__ == "__main__":
    main()
